{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57677f19",
   "metadata": {},
   "source": [
    "# Adaptive Boosting\n",
    "\n",
    "(*Previous knowledge requirement: decision tree, random forest*)\n",
    "\n",
    "## Main Ideas:\n",
    "- 1. Adaboost combines a lot of \"weak learners\" to make classification. Usually, the weak learner is almost always a stump.  Stump: 1 node and 2 leaves, e.g a classification tree based on one feature.\n",
    "\n",
    "- 2. Some stumps get more say in the classification than others, determines the new weight\n",
    "\n",
    "- 3. Each stump is made by(depended on) taking previous stump's mistake into account\n",
    "\n",
    "Basically, we have a weak learner for each feature to classify, choose the feature with the least mistakes(best weighted gini index) in classification, then for the next weak learner, the previously mistaken records would have more amount of say, which means the next weak learner is more priortized to classify the previously mistaken records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2c539",
   "metadata": {},
   "source": [
    "## Detailed realization with mathematical explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e94a9b",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "- **1. n_estimators:** The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early.\n",
    "- **2. base_estimator:** The weak learner, almost always a bump\n",
    "- **3. learning_rate:** Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd78a80",
   "metadata": {},
   "source": [
    "## ScikitLearn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor\n",
    "# algorithm=\"SAMME\", SAMME discrete, \"SAMME.R\", SAMME real number\n",
    "clf =  AdaBoostClassifier(n_estimators=50, learning_rate=1, algorithm=\"SAMME\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
